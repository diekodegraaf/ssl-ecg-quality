{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dAfCypmw0V2"
   },
   "source": [
    "# Lightning bolt\n",
    "youtube video: https://www.youtube.com/watch?v=5irer8A2HoY&list=PL-Pl1R9idzXvfTiMfNJlip2OhbYB5FFrJ&index=9\n",
    "\n",
    "swav github: https://github.com/facebookresearch/swav/blob/main/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SwAV Data transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dieko\\anaconda3\\envs\\ecg\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\Dieko\\anaconda3\\envs\\ecg\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\Dieko\\anaconda3\\envs\\ecg\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "c:\\Users\\Dieko\\anaconda3\\envs\\ecg\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "c:\\Users\\Dieko\\anaconda3\\envs\\ecg\\Lib\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "# adjusted from: https://github.com/Lightning-Universe/lightning-bolts/blob/master/src/pl_bolts/transforms/self_supervised/swav_transforms.py\n",
    "from typing import List, Tuple\n",
    "from torch import Tensor\n",
    "\n",
    "from clinical_ts.create_logger import create_logger\n",
    "\n",
    "from pl_bolts.utils import _TORCHVISION_AVAILABLE\n",
    "from pl_bolts.utils.warnings import warn_missing_pkg\n",
    "\n",
    "if _TORCHVISION_AVAILABLE:\n",
    "    from torchvision import transforms\n",
    "else:  # pragma: no cover\n",
    "    warn_missing_pkg(\"torchvision\")\n",
    "\n",
    "logger = create_logger(__name__)\n",
    "method = \"swav\"\n",
    "\n",
    "class SwAVTrainDataTransform:\n",
    "    def __init__(\n",
    "        self,\n",
    "        normalize=None,\n",
    "        size_crops: Tuple[int] = (96, 36),\n",
    "        num_crops: Tuple[int] = (2, 4),\n",
    "        min_scale_crops: Tuple[float] = (0.33, 0.10),\n",
    "        max_scale_crops: Tuple[float] = (1, 0.33),\n",
    "        gaussian_blur: bool = True,\n",
    "        jitter_strength: float = 1.0,\n",
    "    ) -> None:\n",
    "        self.jitter_strength = jitter_strength\n",
    "        self.gaussian_blur = gaussian_blur\n",
    "\n",
    "        if len(size_crops) != len(num_crops):\n",
    "            raise AssertionError(\"len(size_crops) should equal len(num_crops).\")\n",
    "        if len(min_scale_crops) != len(num_crops):\n",
    "            raise AssertionError(\"len(min_scale_crops) should equal len(num_crops).\")\n",
    "        if len(max_scale_crops) != len(num_crops):\n",
    "            raise AssertionError(\"len(max_scale_crops) should equal len(num_crops).\")\n",
    "\n",
    "        self.size_crops = size_crops\n",
    "        self.num_crops = num_crops\n",
    "        self.min_scale_crops = min_scale_crops\n",
    "        self.max_scale_crops = max_scale_crops\n",
    "\n",
    "        self.color_jitter = transforms.ColorJitter(\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.2 * self.jitter_strength,\n",
    "        )\n",
    "\n",
    "        transform = []\n",
    "        color_transform = [\n",
    "            transforms.RandomApply([self.color_jitter], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2)\n",
    "        ]\n",
    "\n",
    "        if self.gaussian_blur:\n",
    "            kernel_size = int(0.1 * self.size_crops[0])\n",
    "            if kernel_size % 2 == 0:\n",
    "                kernel_size += 1\n",
    "\n",
    "            color_transform.append(\n",
    "                GaussianBlur(kernel_size=kernel_size, p=0.5)\n",
    "            )\n",
    "            # or Resort to torchvision gaussian blur instead of custom implementation\n",
    "            # color_transform.append(transforms.RandomApply([transforms.GaussianBlur(kernel_size=kernel_size)], p=0.5))\n",
    "\n",
    "        self.color_transform = transforms.Compose(color_transform)\n",
    "\n",
    "        if normalize is None:\n",
    "            self.final_transform = transforms.ToTensor()\n",
    "        else:\n",
    "            self.final_transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), normalize])\n",
    "\n",
    "        for i in range(len(self.size_crops)):   # imagenet: (224, 96) [2, 4] (two crops of 224 and 4 of 96)\n",
    "            random_resized_crop = transforms.RandomResizedCrop(\n",
    "                self.size_crops[i],\n",
    "                scale=(self.min_scale_crops[i], self.max_scale_crops[i]),\n",
    "            )\n",
    "\n",
    "            transform.extend(\n",
    "                [\n",
    "                    transforms.Compose(\n",
    "                        [\n",
    "                            random_resized_crop,\n",
    "                            transforms.RandomHorizontalFlip(p=0.5),\n",
    "                            self.color_transform,\n",
    "                            self.final_transform,\n",
    "                        ]\n",
    "                    )\n",
    "                ] * self.num_crops[i]\n",
    "            )\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        # add online train transform of the size of global view\n",
    "        online_train_transform = transforms.Compose([\n",
    "             transforms.RandomResizedCrop(self.size_crops[0]),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             self.final_transform\n",
    "        ])\n",
    "\n",
    "        # return 7 different views ?\n",
    "        self.transform.append(online_train_transform)\n",
    "\n",
    "    def __call__(self, sample: Tensor) -> List[Tensor]:\n",
    "        return [transform(sample) for transform in self.transform]\n",
    "    # video: multi_crops = list(\n",
    "    #     map(lambdfa tranform: transform(sample), self.transform)\n",
    "    # )\n",
    "    # return multi_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwAVEvalDataTransform(SwAVTrainDataTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        normalize=None,\n",
    "        size_crops: Tuple[int] = (96, 36),\n",
    "        num_crops: Tuple[int] = (2, 4),\n",
    "        min_scale_crops: Tuple[float] = (0.33, 0.10),\n",
    "        max_scale_crops: Tuple[float] = (1, 0.33),\n",
    "        gaussian_blur: bool = True,\n",
    "        jitter_strength: float = 1.0,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            normalize=normalize,\n",
    "            size_crops=size_crops,\n",
    "            num_crops=num_crops,\n",
    "            min_scale_crops=min_scale_crops,\n",
    "            max_scale_crops=max_scale_crops,\n",
    "            gaussian_blur=gaussian_blur,\n",
    "            jitter_strength=jitter_strength,\n",
    "        )\n",
    "\n",
    "        input_height = self.size_crops[0]  # get global view crop\n",
    "        test_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(int(input_height + 0.1 * input_height)),\n",
    "                transforms.CenterCrop(input_height),\n",
    "                self.final_transform,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # replace last transform from SwAVTrainDataTransform to eval transform in self.transform list\n",
    "        self.transform[-1] = test_transform\n",
    "\n",
    "\n",
    "class SwAVFinetuneTransform:\n",
    "    def __init__(\n",
    "        self, input_height: int = 224, jitter_strength: float = 1.0, normalize=None, eval_transform: bool = False\n",
    "    ) -> None:\n",
    "        self.jitter_strength = jitter_strength\n",
    "        self.input_height = input_height\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.color_jitter = transforms.ColorJitter(\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.8 * self.jitter_strength,\n",
    "            0.2 * self.jitter_strength,\n",
    "        )\n",
    "\n",
    "        if not eval_transform:\n",
    "            data_transforms = [\n",
    "                transforms.RandomResizedCrop(size=self.input_height),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomApply([self.color_jitter], p=0.8),\n",
    "                transforms.RandomGrayscale(p=0.2),\n",
    "            ]\n",
    "        else:\n",
    "            data_transforms = [\n",
    "                transforms.Resize(\n",
    "                    int(self.input_height + 0.1 * self.input_height)),\n",
    "                transforms.CenterCrop(self.input_height),\n",
    "            ]\n",
    "\n",
    "        if normalize is None:\n",
    "            final_transform = transforms.ToTensor()\n",
    "        else:\n",
    "            final_transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), normalize])\n",
    "\n",
    "        data_transforms.append(final_transform)\n",
    "        self.transform = transforms.Compose(data_transforms)\n",
    "\n",
    "    def __call__(self, sample: Tensor) -> Tensor:\n",
    "        return self.transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behar custom swav resnet \n",
    "\n",
    "Adaptation of : https://github.com/Lightning-Universe/lightning-bolts/blob/master/src/pl_bolts/models/self_supervised/swav/swav_resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9EVWU93sw0V4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import Bottleneck, BasicBlock\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,      # receives model from resnet_simclr\n",
    "            zero_init_residual=False,\n",
    "            output_dim=16,\n",
    "            hidden_mlp=512,\n",
    "            nmb_prototypes=8,\n",
    "            eval_mode=False,\n",
    "            first_conv=True,\n",
    "            maxpool1=True, \n",
    "            l2norm=True\n",
    "    ):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.l2norm = l2norm\n",
    "        self.model = model\n",
    "        self.features = self.model.features\n",
    "        self.projection_head = nn.Sequential(\n",
    "                nn.Linear(512, hidden_mlp),\n",
    "                nn.BatchNorm1d(hidden_mlp),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(hidden_mlp, output_dim),\n",
    "            )\n",
    "\n",
    "        # prototype layer\n",
    "        self.prototypes = None\n",
    "        if isinstance(nmb_prototypes, list):\n",
    "            self.prototypes = MultiPrototypes(output_dim, nmb_prototypes)\n",
    "        elif nmb_prototypes > 0:\n",
    "            self.prototypes = nn.Linear(output_dim, nmb_prototypes, bias=False)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def forward_backbone(self, x):\n",
    "        x = x.type(self.features[0][0].weight.type())\n",
    "        h = self.features(x)\n",
    "        h = h.squeeze()\n",
    "        return h\n",
    "\n",
    "    def forward_head(self, x):\n",
    "        if self.projection_head is not None:\n",
    "            x = self.projection_head(x)\n",
    "\n",
    "        if self.l2norm:\n",
    "            x = nn.functional.normalize(x, dim=1, p=2)\n",
    "\n",
    "        if self.prototypes is not None:\n",
    "            return x, self.prototypes(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if not isinstance(inputs, list):\n",
    "            inputs = [inputs]\n",
    "        idx_crops = torch.cumsum(torch.unique_consecutive(\n",
    "            torch.tensor([inp.shape[-1] for inp in inputs]),\n",
    "            return_counts=True,\n",
    "        )[1], 0)\n",
    "        start_idx = 0\n",
    "        for end_idx in idx_crops:\n",
    "            _out = torch.cat(inputs[start_idx: end_idx])\n",
    "\n",
    "            if 'cuda' in str(self.features[0][0].weight.device):\n",
    "                _out = self.forward_backbone(_out.cuda(non_blocking=True))\n",
    "            else:\n",
    "                _out = self.forward_backbone(_out)\n",
    "\n",
    "            if start_idx == 0:\n",
    "                output = _out\n",
    "            else:\n",
    "                output = torch.cat((output, _out))\n",
    "            start_idx = end_idx\n",
    "        return self.forward_head(output)\n",
    "\n",
    "\n",
    "class MultiPrototypes(nn.Module):\n",
    "    def __init__(self, output_dim, nmb_prototypes):\n",
    "        super(MultiPrototypes, self).__init__()\n",
    "        self.nmb_heads = len(nmb_prototypes)\n",
    "        for i, k in enumerate(nmb_prototypes):\n",
    "            self.add_module(\"prototypes\" + str(i),\n",
    "                            nn.Linear(output_dim, k, bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        for i in range(self.nmb_heads):\n",
    "            out.append(getattr(self, \"prototypes\" + str(i))(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYxnAZnWw0V9"
   },
   "source": [
    "### Augmentations / Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "plT0RQx5w0V-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GlKrW7C2w0V-"
   },
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    #Implements Gaussian blur as described in the SimCLR paper\n",
    "    def __init__(self, kernel_size, p=0.5, min=0.1, max=2.0):\n",
    "        self.min1 = min\n",
    "        self.max = max\n",
    "\n",
    "        # kernel size is set to be 10% of the image height/width\n",
    "        self.kernel_size = kernel_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample = np.array(sample)\n",
    "\n",
    "        # blur the image with a 50% chance\n",
    "        prob = np.random.random_sample()\n",
    "\n",
    "        if prob < self.p:\n",
    "            sigma = (self.max - self.min1) * np.random.random_sample() + self.min1\n",
    "            sample = cv2.GaussianBlur(sample, (self.kernel_size, self.kernel_size), sigma)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrdQe6oVw0WA"
   },
   "source": [
    "### SwAV Module including the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPYhuRNow0WA"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from typing import Callable, Optional\n",
    "import torch\n",
    "import time\n",
    "\n",
    "class CustomSwAV(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        gpus: int,\n",
    "        num_samples: int,\n",
    "        batch_size: int,\n",
    "        config=None,\n",
    "        transformations=None,\n",
    "        nodes: int = 1,\n",
    "        arch: str = 'resnet50',\n",
    "        hidden_mlp: int = 2048,\n",
    "        feat_dim: int = 128,\n",
    "        warmup_epochs: int = 10,\n",
    "        max_epochs: int = 100,\n",
    "        nmb_prototypes: int = 3000,\n",
    "        freeze_prototypes_epochs: int = 1,\n",
    "        temperature: float = 0.1,\n",
    "        sinkhorn_iterations: int = 3,\n",
    "        # queue_length: int = 512,  # must be divisible by total batch-size\n",
    "        queue_path: str = \"queue\",\n",
    "        epoch_queue_starts: int = 15,\n",
    "        crops_for_assign: list = [0, 1],\n",
    "        nmb_crops: list = [2, 6],\n",
    "        first_conv: bool = True,\n",
    "        maxpool1: bool = True,\n",
    "        optimizer: str = 'adam',\n",
    "        lars_wrapper: bool = False,\n",
    "        exclude_bn_bias: bool = False,\n",
    "        start_lr: float = 0.,\n",
    "        learning_rate: float = 1e-3,\n",
    "        final_lr: float = 0.,\n",
    "        weight_decay: float = 1e-6,\n",
    "        epsilon: float = 0.05,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gpus: number of gpus per node used in training, passed to SwAV module\n",
    "                to manage the queue and select distributed sinkhorn\n",
    "            nodes: number of nodes to train on\n",
    "            num_samples: number of image samples used for training\n",
    "            batch_size: batch size per GPU in ddp\n",
    "            dataset: dataset being used for train/val\n",
    "            arch: encoder architecture used for pre-training\n",
    "            hidden_mlp: hidden layer of non-linear projection head, set to 0\n",
    "                to use a linear projection head\n",
    "            feat_dim: output dim of the projection head\n",
    "            warmup_epochs: apply linear warmup for this many epochs\n",
    "            max_epochs: epoch count for pre-training\n",
    "            nmb_prototypes: count of prototype vectors\n",
    "            freeze_prototypes_epochs: epoch till which gradients of prototype layer\n",
    "                are frozen\n",
    "            temperature: loss temperature\n",
    "            sinkhorn_iterations: iterations for sinkhorn normalization\n",
    "            queue_length: set queue when batch size is small,\n",
    "                must be divisible by total batch-size (i.e. total_gpus * batch_size),\n",
    "                set to 0 to remove the queue\n",
    "            queue_path: folder within the logs directory\n",
    "            epoch_queue_starts: start uing the queue after this epoch\n",
    "            crops_for_assign: list of crop ids for computing assignment\n",
    "            nmb_crops: number of global and local crops, ex: [2, 6]\n",
    "            first_conv: keep first conv same as the original resnet architecture,\n",
    "                if set to false it is replace by a kernel 3, stride 1 conv (cifar-10)\n",
    "            maxpool1: keep first maxpool layer same as the original resnet architecture,\n",
    "                if set to false, first maxpool is turned off (cifar10, maybe stl10)\n",
    "            optimizer: optimizer to use\n",
    "            lars_wrapper: use LARS wrapper over the optimizer\n",
    "            exclude_bn_bias: exclude batchnorm and bias layers from weight decay in optimizers\n",
    "            start_lr: starting lr for linear warmup\n",
    "            learning_rate: learning rate\n",
    "            final_lr: float = final learning rate for cosine weight decay\n",
    "            weight_decay: weight decay for optimizer\n",
    "            epsilon: epsilon val for swav assignments\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(\"config\")\n",
    "\n",
    "        self.epoch = 0\n",
    "        self.config = config\n",
    "        self.transformations = transformations\n",
    "        self.gpus = gpus\n",
    "        self.nodes = nodes\n",
    "        self.arch = arch\n",
    "        self.num_samples = num_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.queue_length = 8*batch_size\n",
    "\n",
    "        self.hidden_mlp = hidden_mlp\n",
    "        self.feat_dim = feat_dim\n",
    "        self.nmb_prototypes = nmb_prototypes\n",
    "        self.freeze_prototypes_epochs = freeze_prototypes_epochs\n",
    "        self.sinkhorn_iterations = sinkhorn_iterations\n",
    "\n",
    "        #self.queue_length = queue_length\n",
    "        self.queue_path = queue_path\n",
    "        self.epoch_queue_starts = epoch_queue_starts\n",
    "        self.crops_for_assign = crops_for_assign\n",
    "        self.nmb_crops = nmb_crops\n",
    "\n",
    "        self.first_conv = first_conv\n",
    "        self.maxpool1 = maxpool1\n",
    "\n",
    "        self.optim = optimizer\n",
    "        self.lars_wrapper = lars_wrapper\n",
    "        self.exclude_bn_bias = exclude_bn_bias\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epsilon = epsilon\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.start_lr = start_lr\n",
    "        self.final_lr = final_lr\n",
    "        self.learning_rate = learning_rate\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.max_epochs = config[\"epochs\"]\n",
    "\n",
    "        if self.gpus * self.nodes > 1:\n",
    "            self.get_assignments = self.distributed_sinkhorn\n",
    "        else:\n",
    "            self.get_assignments = self.sinkhorn\n",
    "\n",
    "        \n",
    "        \n",
    "        # compute iters per epoch\n",
    "        global_batch_size = self.nodes * self.gpus * \\\n",
    "            self.batch_size if self.gpus > 0 else self.batch_size\n",
    "        self.train_iters_per_epoch = (self.num_samples // global_batch_size)+1\n",
    "\n",
    "        # define LR schedule\n",
    "        warmup_lr_schedule = np.linspace(\n",
    "            self.start_lr, self.learning_rate, self.train_iters_per_epoch * self.warmup_epochs\n",
    "        )\n",
    "        iters = np.arange(self.train_iters_per_epoch *\n",
    "                          (self.max_epochs - self.warmup_epochs))\n",
    "        cosine_lr_schedule = np.array([self.final_lr + 0.5 * (self.learning_rate - self.final_lr) * (\n",
    "            1 + math.cos(math.pi * t / (self.train_iters_per_epoch *\n",
    "                                        (self.max_epochs - self.warmup_epochs)))\n",
    "        ) for t in iters])\n",
    "\n",
    "        self.lr_schedule = np.concatenate(\n",
    "            (warmup_lr_schedule, cosine_lr_schedule))\n",
    "        self.queue = None   \n",
    "        self.model = self.init_model(model)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def setup(self, stage):\n",
    "        queue_folder = os.path.join(self.config[\"log_dir\"], self.queue_path)\n",
    "\n",
    "        if not os.path.exists(queue_folder):\n",
    "            print(queue_folder)\n",
    "            os.makedirs(queue_folder)\n",
    "\n",
    "        self.queue_path = os.path.join(\n",
    "            queue_folder,\n",
    "            \"queue\" + str(self.trainer.global_rank) + \".pth\"\n",
    "        )\n",
    "\n",
    "        if os.path.isfile(self.queue_path):\n",
    "            self.queue = torch.load(self.queue_path)[\"queue\"]\n",
    "        \n",
    "    def init_model(self, model):\n",
    "        return CustomResNet(model, hidden_mlp=self.hidden_mlp,\n",
    "            output_dim=self.feat_dim,\n",
    "            nmb_prototypes=self.nmb_prototypes,\n",
    "            first_conv=self.first_conv,\n",
    "            maxpool1=self.maxpool1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass single batch from the resnet backbone\n",
    "        return self.model.forward_backbone(x)\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        # # log configuration\n",
    "        # config_str = re.sub(r\"[,\\}\\{]\", \"<br/>\", str(self.config))\n",
    "        # config_str = re.sub(r\"[\\[\\]\\']\", \"\", config_str)\n",
    "        # transformation_str = re.sub(r\"[\\}]\", \"<br/>\", str([\"<br>\" + str(\n",
    "        #     t) + \":<br/>\" + str(t.get_params()) for t in self.transformations]))\n",
    "        # transformation_str = re.sub(r\"[,\\\"\\{\\'\\[\\]]\", \"\", transformation_str)\n",
    "        # self.logger.experiment.add_text(\n",
    "        #     \"configuration\", str(config_str), global_step=0)\n",
    "        # self.logger.experiment.add_text(\"transformations\", str(\n",
    "        #     transformation_str), global_step=0)\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        if self.queue_length > 0:\n",
    "            if self.trainer.current_epoch >= self.epoch_queue_starts and self.queue is None:\n",
    "                self.queue = torch.zeros(\n",
    "                    len(self.crops_for_assign),\n",
    "                    self.queue_length // self.gpus,  # change to nodes * gpus once multi-node\n",
    "                    self.feat_dim,\n",
    "                )\n",
    "\n",
    "                if self.gpus > 0:\n",
    "                    self.queue = self.queue.cuda()\n",
    "\n",
    "        self.use_the_queue = False\n",
    "\n",
    "    def on_train_epoch_end(self):#, outputs) -> None:\n",
    "        if self.queue is not None:\n",
    "            torch.save({\"queue\": self.queue}, self.queue_path)\n",
    "\n",
    "    # def on_epoch_end(self):\n",
    "    def _epoch_end(self):\n",
    "        self.epoch += 1\n",
    "\n",
    "    def on_after_backward(self):\n",
    "        if self.current_epoch < self.freeze_prototypes_epochs:\n",
    "            for name, p in self.model.named_parameters():\n",
    "                if \"prototypes\" in name:\n",
    "                    p.grad = None\n",
    "\n",
    "    def shared_step(self, batch):\n",
    "        \n",
    "        # if self.dataset == 'stl10':\n",
    "        #     unlabeled_batch = batch[0]\n",
    "        #     batch = unlabeled_batch\n",
    "\n",
    "        t0 = time.time()\n",
    "        \n",
    "        inputs, y = batch\n",
    "        # remove online train/eval transforms at this point\n",
    "        inputs = inputs[:-1]\n",
    "        \n",
    "        t1 = time.time()\n",
    "        # 1. normalize the prototypes\n",
    "        with torch.no_grad():\n",
    "            w = self.model.prototypes.weight.data.clone()\n",
    "            w = nn.functional.normalize(w, dim=1, p=2)\n",
    "            self.model.prototypes.weight.copy_(w)\n",
    "        print(f\"Normalize Prototypes: {time.time() - t1:.3f}s\")\n",
    "        \n",
    "        t2 = time.time()\n",
    "        # 2. multi-res forward passes\n",
    "        embedding, output = self.model(inputs)\n",
    "        embedding = embedding.detach()\n",
    "        bs = inputs[0].size(0)\n",
    "        print(f\"Forward Pass: {time.time() - t2:.3f}s\")\n",
    "\n",
    "        t3 = time.time()\n",
    "        # 3. swav loss computation\n",
    "        loss = 0\n",
    "        for i, crop_id in enumerate(self.crops_for_assign):\n",
    "            with torch.no_grad():\n",
    "                out = output[bs * crop_id: bs * (crop_id + 1)]\n",
    "\n",
    "                # 4. time to use the queue\n",
    "                if self.queue is not None:\n",
    "                    if self.use_the_queue or not torch.all(self.queue[i, -1, :] == 0):\n",
    "                        self.use_the_queue = True\n",
    "                        out = torch.cat((torch.mm(\n",
    "                            self.queue[i],\n",
    "                            self.model.prototypes.weight.t()\n",
    "                        ), out))\n",
    "                    # fill the queue\n",
    "                    self.queue[i, bs:] = self.queue[i, :-bs].clone()\n",
    "                    self.queue[i, :bs] = embedding[crop_id *\n",
    "                                                bs: (crop_id + 1) * bs]\n",
    "\n",
    "                # 5. get assignments\n",
    "                q = torch.exp(out / self.epsilon).t()\n",
    "                q = self.get_assignments(q, self.sinkhorn_iterations)[-bs:]\n",
    "\n",
    "            # cluster assignment prediction\n",
    "            subloss = 0\n",
    "            for v in np.delete(np.arange(np.sum(self.nmb_crops-1)), crop_id):\n",
    "                p = self.softmax(\n",
    "                    output[bs * v: bs * (v + 1)] / self.temperature)\n",
    "                loss_value = q * torch.log(p)\n",
    "                subloss -= torch.mean(torch.sum(loss_value, dim=1))\n",
    "            loss += subloss / (np.sum(self.nmb_crops) - 1)\n",
    "        loss /= len(self.crops_for_assign)\n",
    "        print(f\"Swav Loss: {time.time() - t3:.3f}s\")\n",
    "\n",
    "        print(f\"Total shared_step time: {time.time() - t0:.3f}s\")\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx):\n",
    "        # skip the supervised validation loaders\n",
    "        if dataloader_idx != 0:\n",
    "            return {}\n",
    "        loss = self.shared_step(batch)\n",
    "\n",
    "        # self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        results = {\n",
    "            'val_loss': loss,\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # outputs[0] because we are using multiple datasets!\n",
    "        val_loss = mean(outputs[0], 'val_loss')\n",
    "\n",
    "        self.log('val_loss', val_loss, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        log = {\n",
    "            'val_loss': val_loss,\n",
    "        }\n",
    "        return log #{'val_loss': val_loss, 'log': log, 'progress_bar': log}\n",
    "    \n",
    "\n",
    "    def exclude_from_wt_decay(self, named_params, weight_decay, skip_list=['bias', 'bn']):\n",
    "        params = []\n",
    "        excluded_params = []\n",
    "\n",
    "        for name, param in named_params:\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            elif any(layer_name in name for layer_name in skip_list):\n",
    "                excluded_params.append(param)\n",
    "            else:\n",
    "                params.append(param)\n",
    "\n",
    "        return [\n",
    "            {'params': params, 'weight_decay': weight_decay},\n",
    "            {'params': excluded_params, 'weight_decay': 0.}\n",
    "        ]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.exclude_bn_bias:\n",
    "            params = self.exclude_from_wt_decay(\n",
    "                self.named_parameters(),\n",
    "                weight_decay=self.weight_decay\n",
    "            )\n",
    "        else:\n",
    "            params = self.parameters()\n",
    "\n",
    "        if self.optim == 'sgd':\n",
    "            optimizer = torch.optim.SGD(\n",
    "                params,\n",
    "                lr=self.learning_rate,\n",
    "                momentum=0.9,\n",
    "                weight_decay=self.weight_decay\n",
    "            )\n",
    "        elif self.optim == 'adam':\n",
    "            optimizer = torch.optim.Adam(\n",
    "                params,\n",
    "                lr=self.learning_rate,\n",
    "                weight_decay=self.weight_decay\n",
    "            )\n",
    "\n",
    "        if self.lars_wrapper:\n",
    "            optimizer = LARSWrapper(\n",
    "                optimizer,\n",
    "                eta=0.001,  # trust coefficient\n",
    "                clip=False\n",
    "            )\n",
    "\n",
    "        return optimizer\n",
    "    \n",
    "    def optimizer_step(\n",
    "        self,\n",
    "        epoch: int = None,\n",
    "        batch_idx: int = None,\n",
    "        optimizer: Optimizer = None,\n",
    "        optimizer_idx: int = None,\n",
    "        optimizer_closure: Optional[Callable] = None,\n",
    "        on_tpu: bool = None,\n",
    "        using_native_amp: bool = None,\n",
    "        using_lbfgs: bool = None,\n",
    "    ) -> None:\n",
    "        t0 = time.time()\n",
    "        # warm-up + decay schedule placed here since LARSWrapper is not optimizer class\n",
    "        # adjust LR of optim contained within LARSWrapper\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = self.lr_schedule[self.trainer.global_step]\n",
    "\n",
    "        # from lightning\n",
    "        if not isinstance(optimizer, LightningOptimizer):\n",
    "            # wraps into LightingOptimizer only for running step\n",
    "            optimizer = LightningOptimizer.to_lightning_optimizer(optimizer, self.trainer)\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        print(f\"Optimizer step time: {time.time() - t0:.3f}s\")\n",
    "        \n",
    "    def sinkhorn(self, Q, nmb_iters):\n",
    "        with torch.no_grad():\n",
    "            sum_Q = torch.sum(Q)\n",
    "            Q /= sum_Q\n",
    "\n",
    "            K, B = Q.shape\n",
    "\n",
    "            if self.gpus > 0:\n",
    "                u = torch.zeros(K).cuda()\n",
    "                r = torch.ones(K).cuda() / K\n",
    "                c = torch.ones(B).cuda() / B\n",
    "            else:\n",
    "                u = torch.zeros(K)\n",
    "                r = torch.ones(K) / K\n",
    "                c = torch.ones(B) / B\n",
    "\n",
    "            for _ in range(nmb_iters):\n",
    "                u = torch.sum(Q, dim=1)\n",
    "\n",
    "                Q *= (r / u).unsqueeze(1)\n",
    "                Q *= (c / torch.sum(Q, dim=0)).unsqueeze(0)\n",
    "\n",
    "            return (Q / torch.sum(Q, dim=0, keepdim=True)).t().float()\n",
    "\n",
    "    def distributed_sinkhorn(self, Q, nmb_iters):\n",
    "        with torch.no_grad():\n",
    "            sum_Q = torch.sum(Q)\n",
    "            dist.all_reduce(sum_Q)\n",
    "            Q /= sum_Q\n",
    "\n",
    "            if self.gpus > 0:\n",
    "                u = torch.zeros(Q.shape[0]).cuda(non_blocking=True)\n",
    "                r = torch.ones(Q.shape[0]).cuda(non_blocking=True) / Q.shape[0]\n",
    "                c = torch.ones(Q.shape[1]).cuda(\n",
    "                    non_blocking=True) / (self.gpus * Q.shape[1])\n",
    "            else:\n",
    "                u = torch.zeros(Q.shape[0])\n",
    "                r = torch.ones(Q.shape[0]) / Q.shape[0]\n",
    "                c = torch.ones(Q.shape[1]) / (self.gpus * Q.shape[1])\n",
    "\n",
    "            curr_sum = torch.sum(Q, dim=1)\n",
    "            dist.all_reduce(curr_sum)\n",
    "\n",
    "            for it in range(nmb_iters):\n",
    "                u = curr_sum\n",
    "                Q *= (r / u).unsqueeze(1)\n",
    "                Q *= (c / torch.sum(Q, dim=0)).unsqueeze(0)\n",
    "                curr_sum = torch.sum(Q, dim=1)\n",
    "                dist.all_reduce(curr_sum)\n",
    "            return (Q / torch.sum(Q, dim=0, keepdim=True)).t().float()\n",
    "\n",
    "    def type(self):\n",
    "        return self.model.features[0][0].weight.type()\n",
    "\n",
    "    def get_representations(self, x):\n",
    "        return self.model.features(x)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model.model\n",
    "        \n",
    "    def get_device(self):\n",
    "        return self.model.features[0][0].weight.device\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "\n",
    "        # model params\n",
    "        parser.add_argument(\"--arch\", default=\"resnet50\",\n",
    "                            type=str, help=\"convnet architecture\")\n",
    "        # specify flags to store false\n",
    "        parser.add_argument(\"--first_conv\", action='store_false')\n",
    "        parser.add_argument(\"--maxpool1\", action='store_false')\n",
    "        parser.add_argument(\"--hidden_mlp\", default=2048, type=int,\n",
    "                            help=\"hidden layer dimension in projection head\")\n",
    "        parser.add_argument(\"--feat_dim\", default=128,\n",
    "                            type=int, help=\"feature dimension\")\n",
    "        parser.add_argument(\"--online_ft\", action='store_true')\n",
    "        parser.add_argument(\"--fp32\", action='store_true')\n",
    "\n",
    "        # transform params\n",
    "        parser.add_argument(\"--gaussian_blur\",\n",
    "                            action=\"store_true\", help=\"add gaussian blur\")\n",
    "        parser.add_argument(\"--jitter_strength\", type=float,\n",
    "                            default=1.0, help=\"jitter strength\")\n",
    "        parser.add_argument(\"--dataset\", type=str,\n",
    "                            default=\"stl10\", help=\"stl10, cifar10\")\n",
    "        parser.add_argument(\"--data_dir\", type=str,\n",
    "                            default=\".\", help=\"path to download data\")\n",
    "        parser.add_argument(\"--queue_path\", type=str,\n",
    "                            default=\"queue\", help=\"path for queue\")\n",
    "\n",
    "        parser.add_argument(\"--nmb_crops\", type=int, default=[2, 4], nargs=\"+\",\n",
    "                            help=\"list of number of crops (example: [2, 6])\")\n",
    "        parser.add_argument(\"--size_crops\", type=int, default=[96, 36], nargs=\"+\",\n",
    "                            help=\"crops resolutions (example: [224, 96])\")\n",
    "        parser.add_argument(\"--min_scale_crops\", type=float, default=[0.33, 0.10], nargs=\"+\",\n",
    "                            help=\"argument in RandomResizedCrop (example: [0.14, 0.05])\")\n",
    "        parser.add_argument(\"--max_scale_crops\", type=float, default=[1, 0.33], nargs=\"+\",\n",
    "                            help=\"argument in RandomResizedCrop (example: [1., 0.14])\")\n",
    "\n",
    "        # training params\n",
    "        parser.add_argument(\"--fast_dev_run\", action='store_true')\n",
    "        parser.add_argument(\"--nodes\", default=1, type=int,\n",
    "                            help=\"number of nodes for training\")\n",
    "        parser.add_argument(\"--gpus\", default=1, type=int,\n",
    "                            help=\"number of gpus to train on\")\n",
    "        parser.add_argument(\"--num_workers\", default=8,\n",
    "                            type=int, help=\"num of workers per GPU\")\n",
    "        parser.add_argument(\"--optimizer\", default=\"adam\",\n",
    "                            type=str, help=\"choose between adam/sgd\")\n",
    "        parser.add_argument(\"--lars_wrapper\", action='store_true',\n",
    "                            help=\"apple lars wrapper over optimizer used\")\n",
    "        parser.add_argument('--exclude_bn_bias', action='store_true',\n",
    "                            help=\"exclude bn/bias from weight decay\")\n",
    "        parser.add_argument(\"--max_epochs\", default=100,\n",
    "                            type=int, help=\"number of total epochs to run\")\n",
    "        parser.add_argument(\"--max_steps\", default=-1,\n",
    "                            type=int, help=\"max steps\")\n",
    "        parser.add_argument(\"--warmup_epochs\", default=10,\n",
    "                            type=int, help=\"number of warmup epochs\")\n",
    "        parser.add_argument(\"--batch_size\", default=128,\n",
    "                            type=int, help=\"batch size per gpu\")\n",
    "\n",
    "        parser.add_argument(\"--weight_decay\", default=1e-6,\n",
    "                            type=float, help=\"weight decay\")\n",
    "        parser.add_argument(\"--learning_rate\", default=1e-3,\n",
    "                            type=float, help=\"base learning rate\")\n",
    "        parser.add_argument(\"--start_lr\", default=0, type=float,\n",
    "                            help=\"initial warmup learning rate\")\n",
    "        parser.add_argument(\"--final_lr\", type=float,\n",
    "                            default=1e-6, help=\"final learning rate\")\n",
    "\n",
    "        # swav params\n",
    "        parser.add_argument(\"--crops_for_assign\", type=int, nargs=\"+\", default=[0, 1],\n",
    "                            help=\"list of crops id used for computing assignments\")\n",
    "        parser.add_argument(\"--temperature\", default=0.1, type=float,\n",
    "                            help=\"temperature parameter in training loss\")\n",
    "        parser.add_argument(\"--epsilon\", default=0.05, type=float,\n",
    "                            help=\"regularization parameter for Sinkhorn-Knopp algorithm\")\n",
    "        parser.add_argument(\"--sinkhorn_iterations\", default=3, type=int,\n",
    "                            help=\"number of iterations in Sinkhorn-Knopp algorithm\")\n",
    "        parser.add_argument(\"--nmb_prototypes\", default=512,\n",
    "                            type=int, help=\"number of prototypes\")\n",
    "        parser.add_argument(\"--queue_length\", type=int, default=0,\n",
    "                            help=\"length of the queue (0 for no queue); must be divisible by total batch size\")\n",
    "        parser.add_argument(\"--epoch_queue_starts\", type=int, default=15,\n",
    "                            help=\"from this epoch, we start using a queue\")\n",
    "        parser.add_argument(\"--freeze_prototypes_epochs\", default=1, type=int,\n",
    "                            help=\"freeze the prototypes during this many epochs from the start\")\n",
    "\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mkrSK8H1w0WB"
   },
   "outputs": [],
   "source": [
    "# # args\n",
    "# dataset = 'stl10'\n",
    "# batch_size = 64\n",
    "# num_workers = 0\n",
    "\n",
    "\n",
    "# # datamodule args for STL\n",
    "# size_crops = [96, 36]\n",
    "# num_crops = [2, 4]\n",
    "# min_scale_crops = [0.33, 0.10]\n",
    "# max_scale_crops = [1, 0.33]\n",
    "# gaussian_blur = True\n",
    "# jitter_strength = 1.0\n",
    "\n",
    "# hidden_mlp = 2048\n",
    "# feat_dim = 128\n",
    "# max_epochs = 100\n",
    "# warmup_epochs = 10\n",
    "# num_prototypes = 512\n",
    "\n",
    "# freeze_prototypes_epochs = 1\n",
    "# temperature = 0.1\n",
    "# optimizer = 'adam'\n",
    "# learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre and post train + main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "from argparse import ArgumentParser\n",
    "from typing import Callable, Optional\n",
    "import pdb\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "# from pytorch_lightning.utilities import AMPType\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.optimizer import LightningOptimizer\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import yaml\n",
    "import time\n",
    "import logging\n",
    "import pickle\n",
    "# from pl_bolts.models.self_supervised.swav.swav_resnet import resnet18, resnet50\n",
    "# from pl_bolts.optimizers.lars_scheduling import LARSWrapper\n",
    "from pl_bolts.transforms.dataset_normalizations import (\n",
    "    cifar10_normalization,\n",
    "    imagenet_normalization,\n",
    "    stl10_normalization,\n",
    ")\n",
    "from clinical_ts.simclr_dataset_wrapper import SimCLRDataSetWrapper\n",
    "from clinical_ts.create_logger import create_logger\n",
    "from torchvision.models.resnet import Bottleneck, BasicBlock\n",
    "from online_evaluator import SSLOnlineEvaluator\n",
    "from ecg_datamodule import ECGDataModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from models.resnet_simclr import ResNetSimCLR\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "_TORCHVISION_AVAILABLE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLF-rjLsw0WC",
    "outputId": "401ad801-7200-4906-9b00-34ca810daee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(trafos=['GaussianNoise'], gaussian_scale=0.01, rr_crop_ratio_range=[0.5, 1.0], output_size=250, warps=3, radius=10, epsilon=10, magnitude_range=[0.5, 2], downsample_ratio=0.2, to_crop_ratio_range=[0.2, 0.4], resume=False, gpus=1, num_nodes=1, distributed_backend=None, batch_size=None, epochs=None, debug=False, warm_up=1, precision=None, target_folders=None, log_dir='./experiment_logs', percentage=1.0, lr=None, out_dim=None, filter_cinc=False, base_model=None, widen=None, run_callbacks=False, checkpoint_path='')\n",
      "{'batch_size': 512, 'epochs': 1, 'warm_up': 1, 'eval_every_n_epochs': 1, 'fine_tune_from': 'None', 'log_every_n_steps': 50, 'lr': '5e-4', 'weight_decay': '1e-3', 'precision': 32, 'log_dir': './experiment_logs\\\\04-04-2025-11-57_swav_GN_var=0.01', 'debug': False, 'model': {'out_dim': 16, 'base_model': 'xresnet1d50', 'hidden': True, 'widen': 1.0}, 'loss': {'temperature': 0.5, 'use_cosine_similarity': True}, 'dataset': {'num_workers': 2, 'data_path': './data/but-qdb/brno-university-of-technology-ecg-quality-database-but-qdb-1.0.0', 'signal_fs': 100, 'train_records': ['104001', '105001', '115001', '118001', '121001', '125001', '126001'], 'val_records': ['103001', '103002', '103003', '111001', '113001', '123001'], 'test_records': ['100001', '100002', '114001', '122001', '124001'], 'swav': True, 'num_crops': 7}, 'eval_epochs': 5, 'eval_every': 15, 'eval_batch_size': 512, 'lin_eval_every_n_epochs': 1, 'eval_lr': '5e-3', 'eval_wd': '1e-3', 'perform_lin_eval': True, 'perform_fine_tuning': True, 'eval_mode': 'fine_tuning', 'eval_gradual_freezing': False, 'output_size': 250, 'run_callbacks': False, 'checkpoint_path': '', 'trafos': ['GaussianNoise'], 'warps': 3, 'downsample_ratio': 0.2, 'distributed_backend': None, 'gaussian_scale': 0.01, 'magnitude_range': [0.5, 2], 'to_crop_ratio_range': [0.2, 0.4], 'percentage': 1.0, 'base_model': None, 'rr_crop_ratio_range': [0.5, 1.0], 'filter_cinc': False, 'target_folders': None, 'gpus': 1, 'widen': None, 'epsilon': 10, 'out_dim': None, 'resume': False, 'num_nodes': 1, 'radius': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dieko\\anaconda3\\envs\\ecg\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes Trainloaders [526]\n",
      "Sizes Valloaders [78, 118, 78]\n",
      "Data module num workers 2\n",
      "Batch size 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | model   | CustomResNet | 2.9 M \n",
      "1 | softmax | Softmax      | 0     \n",
      "-----------------------------------------\n",
      "2.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.426    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experiment_logs\\04-04-2025-11-57_swav_GN_var=0.01\\queue\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9314bb32b6d544aa93133cad0e2493d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize Prototypes: 0.001s\n",
      "Forward Pass: 0.022s\n",
      "Swav Loss: 0.393s\n",
      "Total shared_step time: 0.417s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.011s\n",
      "Swav Loss: 0.180s\n",
      "Total shared_step time: 0.190s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d55801dff2f4faeab0f9bbabec00e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train epoch start: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dieko\\anaconda3\\envs\\ecg\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:362: LightningDeprecationWarning: The NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0. The `CustomSwAV.optimizer_step()` hook is overridden, including the `using_native_amp` argument. Removing this argument will avoid this message, you can expect it to return True.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.081s\n",
      "Swav Loss: 0.225s\n",
      "Total shared_step time: 0.307s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.381s\n",
      "Normalize Prototypes: 0.001s\n",
      "Forward Pass: 0.017s\n",
      "Swav Loss: 0.193s\n",
      "Total shared_step time: 0.211s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.231s\n",
      "Normalize Prototypes: 0.001s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.194s\n",
      "Total shared_step time: 0.208s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.237s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.011s\n",
      "Swav Loss: 0.196s\n",
      "Total shared_step time: 0.207s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.229s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.197s\n",
      "Total shared_step time: 0.209s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.234s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.015s\n",
      "Swav Loss: 0.193s\n",
      "Total shared_step time: 0.209s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.229s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.197s\n",
      "Total shared_step time: 0.209s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.232s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.195s\n",
      "Total shared_step time: 0.207s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.226s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.195s\n",
      "Total shared_step time: 0.207s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.226s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.014s\n",
      "Swav Loss: 0.192s\n",
      "Total shared_step time: 0.206s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.226s\n",
      "Normalize Prototypes: 0.001s\n",
      "Forward Pass: 0.011s\n",
      "Swav Loss: 0.196s\n",
      "Total shared_step time: 0.208s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.228s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.195s\n",
      "Total shared_step time: 0.208s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.228s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.193s\n",
      "Total shared_step time: 0.207s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.227s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.194s\n",
      "Total shared_step time: 0.208s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.227s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.014s\n",
      "Swav Loss: 0.194s\n",
      "Total shared_step time: 0.209s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.228s\n",
      "Normalize Prototypes: 0.001s\n",
      "Forward Pass: 0.017s\n",
      "Swav Loss: 0.194s\n",
      "Total shared_step time: 0.212s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.231s\n",
      "Normalize Prototypes: 0.001s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.204s\n",
      "Total shared_step time: 0.218s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.239s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.200s\n",
      "Total shared_step time: 0.213s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.231s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.015s\n",
      "Swav Loss: 0.194s\n",
      "Total shared_step time: 0.209s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.232s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.012s\n",
      "Swav Loss: 0.201s\n",
      "Total shared_step time: 0.214s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.232s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.011s\n",
      "Swav Loss: 0.194s\n",
      "Total shared_step time: 0.206s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.225s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.013s\n",
      "Swav Loss: 0.194s\n",
      "Total shared_step time: 0.208s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.226s\n",
      "Normalize Prototypes: 0.000s\n",
      "Forward Pass: 0.014s\n",
      "Swav Loss: 0.195s\n",
      "Total shared_step time: 0.209s\n",
      "On after backward: 0.001s\n",
      "Optimizer step time: 0.228s\n",
      "Normalize Prototypes: 0.001s\n",
      "Forward Pass: 0.011s\n",
      "Swav Loss: 0.197s\n",
      "Total shared_step time: 0.208s\n",
      "On after backward: 0.000s\n",
      "Optimizer step time: 0.226s\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "import logging\n",
    "\n",
    "from clinical_ts.simclr_dataset_wrapper import transformations_from_strings\n",
    "\n",
    "\n",
    "def mean(res, key1, key2=None):\n",
    "    if key2 is not None:\n",
    "        return torch.stack([x[key1][key2] for x in res]).mean()\n",
    "    return torch.stack([x[key1] for x in res if type(x) == dict and key1 in x.keys()]).mean()\n",
    "\n",
    "def parse_args(parent_parser):\n",
    "    parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "    parser.add_argument('-t', '--trafos', nargs='+', help='add transformation to data augmentation pipeline',\n",
    "                        default=[\"GaussianNoise\", \"ChannelResize\", \"RandomResizedCrop\"])\n",
    "    # GaussianNoise\n",
    "    parser.add_argument(\n",
    "            '--gaussian_scale', help='std param for gaussian noise transformation', default=0.005, type=float)\n",
    "    # RandomResizedCrop\n",
    "    parser.add_argument('--rr_crop_ratio_range',\n",
    "                            help='ratio range for random resized crop transformation', default=[0.5, 1.0], type=float)\n",
    "    parser.add_argument(\n",
    "            '--output_size', help='output size for random resized crop transformation', default=250, type=int)\n",
    "    # DynamicTimeWarp\n",
    "    parser.add_argument(\n",
    "            '--warps', help='number of warps for dynamic time warp transformation', default=3, type=int)\n",
    "    parser.add_argument(\n",
    "            '--radius', help='radius of warps of dynamic time warp transformation', default=10, type=int)\n",
    "    # TimeWarp\n",
    "    parser.add_argument(\n",
    "            '--epsilon', help='epsilon param for time warp', default=10, type=float)\n",
    "    # ChannelResize\n",
    "    parser.add_argument('--magnitude_range', nargs='+',\n",
    "                            help='range for scale param for ChannelResize transformation', default=[0.5, 2], type=float)\n",
    "    # Downsample\n",
    "    parser.add_argument(\n",
    "            '--downsample_ratio', help='downsample ratio for Downsample transformation', default=0.2, type=float)\n",
    "    # TimeOut\n",
    "    parser.add_argument('--to_crop_ratio_range', nargs='+',\n",
    "                            help='ratio range for timeout transformation', default=[0.2, 0.4], type=float)\n",
    "    # resume training\n",
    "    parser.add_argument('--resume', action='store_true')\n",
    "    parser.add_argument(\n",
    "            '--gpus', help='number of gpus to use; use cpu if gpu=0', type=int, default=1)\n",
    "    parser.add_argument(\n",
    "            '--num_nodes', default=1, help='number of cluster nodes', type=int)\n",
    "    parser.add_argument(\n",
    "            '--distributed_backend', help='sets backend type')\n",
    "    parser.add_argument('--batch_size', type=int)\n",
    "    parser.add_argument('--epochs', type=int)\n",
    "    parser.add_argument('--debug', action='store_true')\n",
    "    parser.add_argument('--warm_up', default=1, type=int)\n",
    "    parser.add_argument('--precision', type=int)\n",
    "    parser.add_argument('--datasets', dest=\"target_folders\",\n",
    "                            nargs='+', help='used datasets for pretraining')\n",
    "    parser.add_argument('--log_dir', default=\"./experiment_logs\")\n",
    "    parser.add_argument(\n",
    "            '--percentage', help='determines how much of the dataset shall be used during the pretraining', type=float, default=1.0)\n",
    "    parser.add_argument('--lr', type=float, help=\"learning rate\")\n",
    "    parser.add_argument('--out_dim', type=int, help=\"output dimension of model\")\n",
    "    parser.add_argument('--filter_cinc', action=\"store_true\", help=\"only valid if cinc is selected: filter out the ptb data\", default=False )\n",
    "    parser.add_argument('--base_model')\n",
    "    parser.add_argument('--widen',type=int, help=\"use wide xresnet1d50\")\n",
    "    parser.add_argument('--run_callbacks', default=False, action=\"store_true\", help=\"run callbacks which asses linear evaluaton and finetuning metrics during pretraining\")\n",
    "\n",
    "    parser.add_argument('--checkpoint_path', default=\"\")\n",
    "    return parser\n",
    "\n",
    "def init_logger(config):\n",
    "    level = logging.INFO\n",
    "\n",
    "    if config['debug']:\n",
    "        level = logging.DEBUG\n",
    "\n",
    "    # remove all handlers to change basic configuration\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    if not os.path.isdir(config['log_dir']):\n",
    "        os.mkdir(config['log_dir'])\n",
    "    logging.basicConfig(filename=os.path.join(config['log_dir'], 'info.log'), level=level,\n",
    "                        format='%(asctime)s %(name)s:%(lineno)s %(levelname)s:  %(message)s  ')\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "def init_logger(config):\n",
    "    level = logging.DEBUG if config.get('debug', False) else logging.INFO\n",
    "    log_dir = config.get('log_dir', './experiment_logs')\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # check if handlers already exist, prevent reinitialization\n",
    "    if not logger.hasHandlers():\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "        # remove existing handlers from root logger\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)\n",
    "\n",
    "        logging.basicConfig(\n",
    "            filename=os.path.join(log_dir, 'info.log'),\n",
    "            level=level,\n",
    "            format='%(asctime)s %(name)s:%(lineno)d %(levelname)s: %(message)s'\n",
    "        )\n",
    "        logger.info(\"Logger initialized.\")\n",
    "    return logger\n",
    "\n",
    "\n",
    "def  pretrain_routine(args):\n",
    "        \n",
    "    checkpoint_config = os.path.join(\"checkpoints\", \"bolts_config.yaml\")\n",
    "    config_file = checkpoint_config if args.resume and os.path.isfile(\n",
    "        checkpoint_config) else \"bolts_config.yaml\"\n",
    "    config = yaml.load(open(config_file, \"r\"), Loader=yaml.FullLoader)\n",
    "    args_dict = vars(args)\n",
    "    for key in set(config.keys()).union(set(args_dict.keys())):\n",
    "        config[key] = config[key] if (key not in args_dict.keys() or key in args_dict.keys(\n",
    "        ) and key in config.keys() and args_dict[key] is None) else args_dict[key]\n",
    "\n",
    "    if args.target_folders is not None:\n",
    "        config[\"dataset\"][\"target_folders\"] = args.target_folders\n",
    "        \n",
    "    # print(config[\"dataset\"][\"filter_cinc\"])\n",
    "    config[\"model\"][\"base_model\"] = args.base_model if args.base_model is not None else config[\"model\"][\"base_model\"]\n",
    "    config[\"model\"][\"widen\"] = args.widen if args.widen is not None else config[\"model\"][\"widen\"]\n",
    "    \n",
    "    config[\"dataset\"][\"swav\"] = True\n",
    "    config[\"dataset\"][\"num_crops\"] = 7\n",
    "    # print(config[\"dataset\"].keys())\n",
    "    # config[\"eval_dataset\"][\"swav\"] = True\n",
    "    # config[\"eval_dataset\"][\"num_crops\"] = 7\n",
    "    logger = init_logger(config)\n",
    "    \n",
    "    # transformations\n",
    "    t_params = {\"gaussian_scale\": args.gaussian_scale, \"rr_crop_ratio_range\": args.rr_crop_ratio_range, \"output_size\": args.output_size, \"warps\": args.warps, \"radius\": args.radius,\n",
    "                \"epsilon\": args.epsilon, \"magnitude_range\": args.magnitude_range, \"downsample_ratio\": args.downsample_ratio, \"to_crop_ratio_range\": args.to_crop_ratio_range,\n",
    "                \"bw_cmax\":0.1, \"em_cmax\":0.5, \"pl_cmax\":0.2, \"bs_cmax\":1}\n",
    "    transformations = args.trafos\n",
    "\n",
    "    # get processed transforms for strings and their set params\n",
    "    processed_transformations = transformations_from_strings(transformations, t_params)\n",
    "    for i, t in enumerate(processed_transformations):\n",
    "        logger.info(str(i) + \". Transformation: \" +\n",
    "                    str(t) + \": \" + str(t.get_params()))\n",
    "\n",
    "    params_list = [t.get_params() for t in processed_transformations]\n",
    "        \n",
    "    if args.out_dim is not None:\n",
    "        config[\"model\"][\"out_dim\"] = args.out_dim\n",
    "    \n",
    "    # print(config['batch_size'], [*config['dataset']], transformations, t_params)\n",
    "    \n",
    "\n",
    "    date = time.asctime()\n",
    "    abr = {\"Transpose\": \"Tr\", \"TimeOut\": \"TO\", \"DynamicTimeWarp\": \"DTW\", \"RandomResizedCrop\": \"RRC\", \"ChannelResize\": \"ChR\", \"GaussianNoise\": \"GN\",\n",
    "           \"TimeWarp\": \"TW\", \"ToTensor\": \"TT\", \"GaussianBlur\": \"GB\", \"BaselineWander\": \"BlW\", \"PowerlineNoise\": \"PlN\", \"EMNoise\": \"EM\", \"BaselineShift\": \"BlS\"}\n",
    "    trs = re.sub(r\"[,'\\]\\[]\", \"\", str([abr[str(tr)] if abr[str(tr)] not in [\n",
    "                 \"TT\", \"Tr\"] else '' for tr in processed_transformations]))\n",
    "    formatted_params = [f'{k}={v}' for item in params_list[1:] for k, v in item.items()]\n",
    "    name = time.strftime(\"%d-%m-%Y-%H-%M\") + \"_\" + method + \"_\" + trs[1:].strip() + '_' + '_'.join(formatted_params)\n",
    "    # + str(time.time_ns())[-3:] + \"_\" + trs[1:].strip()\n",
    "\n",
    "    tb_logger = TensorBoardLogger(args.log_dir, name=name, version='')\n",
    "    config[\"log_dir\"] = os.path.join(args.log_dir, name)\n",
    "    print(config)\n",
    "    return config, transformations, t_params, tb_logger\n",
    "\n",
    "def aftertrain_routine(config, args, trainer, pl_model, datamodule, callbacks):\n",
    "    # save best fine-tuned and linear evaluation model\n",
    "    scores = {}\n",
    "    for ca in callbacks:\n",
    "        if isinstance(ca, SSLOnlineEvaluator):\n",
    "            scores[str(ca)] = {\"macro\": ca.best_macro}\n",
    "\n",
    "    results = {\"config\": config, \"trafos\": args.trafos, \"scores\": scores}\n",
    "\n",
    "    with open(os.path.join(config[\"log_dir\"], \"results.pkl\"), 'wb') as handle:\n",
    "        pickle.dump(results, handle)\n",
    "\n",
    "    # if callbacks disabled, this saves the last state of the pre-trained model\n",
    "    # otherwise the fine-tuned/linear eval model. which of the 2?\n",
    "    trainer.save_checkpoint(os.path.join(config[\"log_dir\"], \"checkpoints\", \"model.ckpt\"))\n",
    "    with open(os.path.join(config[\"log_dir\"], \"config.txt\"), \"w\") as text_file:\n",
    "        print(config, file=text_file)\n",
    "\n",
    "import argparse\n",
    "\n",
    "# Simulated parsed arguments with default values\n",
    "args = argparse.Namespace(\n",
    "    trafos=[\"GaussianNoise\"],#, \"ChannelResize\"],# \"RandomResizedCrop\"],\n",
    "    gaussian_scale=0.01,\n",
    "    rr_crop_ratio_range=[0.5, 1.0],\n",
    "    output_size=250,\n",
    "    warps=3,\n",
    "    radius=10,\n",
    "    epsilon=10,\n",
    "    magnitude_range=[0.5, 2],\n",
    "    downsample_ratio=0.2,\n",
    "    to_crop_ratio_range=[0.2, 0.4],\n",
    "    resume=False,\n",
    "    gpus=1,\n",
    "    num_nodes=1,\n",
    "    distributed_backend=None,\n",
    "    batch_size=None,       # Set a value if needed, e.g., 64\n",
    "    epochs=None,           # Set a value if needed, e.g., 100\n",
    "    debug=False,\n",
    "    warm_up=1,\n",
    "    precision=None,        # Set a value if needed, e.g., 32\n",
    "    target_folders=None,   # Or a list of folder names if applicable\n",
    "    log_dir=\"./experiment_logs\",\n",
    "    percentage=1.0,\n",
    "    lr=None,               # Set a value if needed, e.g., 0.001\n",
    "    out_dim=None,          # Set a value if needed, e.g., 128\n",
    "    filter_cinc=False,\n",
    "    base_model=None,\n",
    "    widen=None,            # Set a value if needed, e.g., 2\n",
    "    run_callbacks=False,\n",
    "    checkpoint_path=\"\"\n",
    ")\n",
    "\n",
    "# You can now pass 'args' to your next step:\n",
    "print(args)\n",
    "\n",
    "\n",
    "def cli_main():\n",
    "    from pytorch_lightning import Trainer\n",
    "    from online_evaluator import SSLOnlineEvaluator\n",
    "    from ecg_datamodule import ECGDataModule\n",
    "    from clinical_ts.create_logger import create_logger\n",
    "    from os.path import exists\n",
    "    from pytorch_lightning.profilers import SimpleProfiler, AdvancedProfiler\n",
    "    \n",
    "    # parser = ArgumentParser()\n",
    "    # parser = parse_args(parser)\n",
    "    logger.info(\"parse arguments\")\n",
    "    # args = parser.parse_args()\n",
    "    config, transformations, t_params, tb_logger = pretrain_routine(args)\n",
    "    # print('Output datafolder', config[\"dataset\"][\"data_folder\"])\n",
    "    \n",
    "    # data\n",
    "\n",
    "    ecg_datamodule = ECGDataModule(config, transformations, t_params)\n",
    "    \n",
    "    train_loaders = ecg_datamodule.train_dataloader()\n",
    "    val_loaders = ecg_datamodule.val_dataloader()\n",
    "    if type(train_loaders) == list:\n",
    "        print('Sizes Trainloaders', [len(x) for x in train_loaders])\n",
    "    else:\n",
    "        print('Sizes Trainloaders', [len(train_loaders)])\n",
    "    if type(val_loaders) == list:\n",
    "        print('Sizes Valloaders', [len(x) for x in val_loaders])\n",
    "    else:\n",
    "        print('Sizes Valloaders', [len(val_loaders)])\n",
    "    print('Data module num workers', ecg_datamodule.num_workers)\n",
    "    print('Batch size', ecg_datamodule.batch_size)\n",
    "\n",
    "    callbacks = []\n",
    "    if args.run_callbacks:\n",
    "        # callback for supervised online linear evaluation and fine-tuning\n",
    "        linear_evaluator = SSLOnlineEvaluator(drop_p=0, z_dim=512, num_classes=ecg_datamodule.num_classes, hidden_dim=None, \n",
    "                                              lin_eval_epochs=config[\"eval_epochs\"], eval_every=config[\"eval_every\"], mode=\"linear_evaluation\", verbose=False)\n",
    "\n",
    "        fine_tuner = SSLOnlineEvaluator(drop_p=0, z_dim=512, num_classes=ecg_datamodule.num_classes, hidden_dim=None, \n",
    "                                        lin_eval_epochs=config[\"eval_epochs\"], eval_every=config[\"eval_every\"], mode=\"fine_tuning\", verbose=False)\n",
    "   \n",
    "        callbacks.append(linear_evaluator)\n",
    "        callbacks.append(fine_tuner)\n",
    "\n",
    "    # callback for saving the best pre-trained model based on lowest validation loss\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',    # first validation loader is for pre-train\n",
    "        mode='min',          \n",
    "        save_top_k=1,        \n",
    "        dirpath=os.path.join(config[\"log_dir\"], \"checkpoints\"),\n",
    "        filename='best_pretrained_swav_{epoch}-{val_loss:.4f}'\n",
    "    )\n",
    "    callbacks.append(checkpoint_callback)\n",
    "    \n",
    "    # Example: using the SimpleProfiler\n",
    "    simple_profiler = SimpleProfiler(dirpath=\".\", filename=\"simple_profiler3.txt\")\n",
    "\n",
    "    # configure trainer\n",
    "    trainer = Trainer(logger=tb_logger, max_epochs=config[\"epochs\"], gpus=args.gpus,\n",
    "                      strategy=args.distributed_backend, auto_lr_find=False, num_nodes=args.num_nodes, \n",
    "                      precision=config[\"precision\"], callbacks=callbacks, profiler=simple_profiler)\n",
    "    # trainer = Trainer(logger=tb_logger, max_epochs=config[\"epochs\"], gpus=args.gpus,\n",
    "    #                 distributed_backend=args.distributed_backend, auto_lr_find=False, num_nodes=args.num_nodes, precision=config[\"precision\"], callbacks=callbacks)\n",
    "\n",
    "    # pytorch lightning module\n",
    "    model = ResNetSimCLR(**config[\"model\"])\n",
    "    pl_model = CustomSwAV(model,  config[\"gpus\"], ecg_datamodule.num_samples, config[\"batch_size\"], config=config,\n",
    "                              transformations=ecg_datamodule.transformations, nmb_crops=config[\"dataset\"][\"num_crops\"], optimizer='adam')\n",
    "    # load checkpoint\n",
    "    if args.checkpoint_path != \"\":\n",
    "        if exists(args.checkpoint_path):\n",
    "            logger.info(\"Retrieve checkpoint from \" + args.checkpoint_path)\n",
    "            pl_model.load_from_checkpoint(args.checkpoint_path)\n",
    "        else:\n",
    "            raise(\"checkpoint does not exist\")\n",
    "\n",
    "    # start training\n",
    "    trainer.fit(pl_model, ecg_datamodule)\n",
    "\n",
    "    \n",
    "    aftertrain_routine(config, args, trainer, pl_model, ecg_datamodule, callbacks)\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    cli_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welke metrics heb ik nodig tijdens pre-train voornamelijk? Allemaal unsupervised dus gebruik alleen de loss.\n",
    "\n",
    "### 4. Summary of Metrics\n",
    "The `SSLOnlineEvaluator` computes and logs the following metrics during **linear evaluation** and **fine-tuning**:\n",
    "\n",
    "| **Metric**            | **Purpose**                                                                 | **Logged As**               |\n",
    "|------------------------|-----------------------------------------------------------------------------|-----------------------------|\n",
    "| **Binary Cross-Entropy Loss** | Tracks the linear head's performance during training and evaluation.       | `<log_key>_mlp/loss`        |\n",
    "| **Macro ROC AUC**      | Measures the classification performance of the linear head.                | `<log_key>_mlp/macro`       |\n",
    "| **Best Macro ROC AUC** | Tracks the best ROC AUC score achieved during evaluation.                  | `<log_key>_mlp/best_macro`  |\n",
    "\n",
    "These metrics are logged and can be visualized using tools like TensorBoard or WandB to monitor the model's performance during **linear evaluation** or **fine-tuning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())  # Total CPU cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is as follows: the config is given to ECGDataModule and then used in the simclrdatawrapper, however the module is setting its own parameters like batch size besides the config.... which is strange\n",
    "\n",
    "Fixed but still why 1952 in 1 epoch??? because 3 valloaders [450, 526, 450]\n",
    "\n",
    "why 3 valloaders and when does test come in? requirements of loaders per step... are?\n",
    "\n",
    "return [valid_loader_self, valid_loader_sup, test_loader_sup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Check why epoch size is 1952? with batch 512? omdat hij de twee validation loaders er bij optelt. = 450 + 450 = 900 \n",
    "526 + 900 = 1426 laat 526 over.... duss validation dataloader 1 & 2 en nog eens train??? of wat dan?\n",
    "- alleen val_loss/dataloader_idx_0 wordt geplot, geen echte metric ofzo.\n",
    "- training steps gaan idd door in epoch1 .\n",
    "- fix the evaluation datasets with correct labels!!\n",
    "- Log the correct statistics, every 200 evaluation?\n",
    "- Fix the augmentations...!\n",
    "- set the parameters to the paper, batch size etc.\n",
    "- Optimize runspeed\n",
    "\n",
    "- Run on SNELLISUS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 512, 'epochs': 1, 'warm_up': 1, 'eval_every_n_epochs': 1, 'fine_tune_from': 'None', 'log_every_n_steps': 50, 'lr': '5e-4', 'weight_decay': '1e-3', 'precision': 32, 'log_dir': './experiment_logs\\\\04-04-2025-10-05_swav_GN_var=0.01', 'debug': False, 'model': {'out_dim': 16, 'base_model': 'xresnet1d50', 'hidden': True, 'widen': 1.0}, 'loss': {'temperature': 0.5, 'use_cosine_similarity': True}, 'dataset': {'num_workers': 2, 'data_path': './data/but-qdb/brno-university-of-technology-ecg-quality-database-but-qdb-1.0.0', 'signal_fs': 100, 'train_records': ['104001', '105001', '115001', '118001', '121001', '125001', '126001'], 'val_records': ['103001', '103002', '103003', '111001', '113001', '123001'], 'test_records': ['100001', '100002', '114001', '122001', '124001'], 'swav': True, 'num_crops': 7}, 'eval_epochs': 5, 'eval_every': 15, 'eval_batch_size': 512, 'lin_eval_every_n_epochs': 1, 'eval_lr': '5e-3', 'eval_wd': '1e-3', 'perform_lin_eval': True, 'perform_fine_tuning': True, 'eval_mode': 'fine_tuning', 'eval_gradual_freezing': False, 'run_callbacks': False, 'target_folders': None, 'filter_cinc': False, 'output_size': 250, 'percentage': 1.0, 'to_crop_ratio_range': [0.2, 0.4], 'out_dim': None, 'trafos': ['GaussianNoise'], 'gpus': 1, 'rr_crop_ratio_range': [0.5, 1.0], 'warps': 3, 'gaussian_scale': 0.01, 'distributed_backend': None, 'checkpoint_path': '', 'epsilon': 10, 'widen': None, 'base_model': None, 'num_nodes': 1, 'resume': False, 'radius': 10, 'downsample_ratio': 0.2, 'magnitude_range': [0.5, 2]}\n",
      "batches in pre-train training loader 526\n",
      "batches in pre-train  validation loader 78\n",
      "batches in supervised training loader 118\n",
      "batches in supervised validation loader 78\n",
      "batches in supervised test loader 77\n"
     ]
    }
   ],
   "source": [
    "from clinical_ts.simclr_dataset_wrapper import SimCLRDataSetWrapper  \n",
    "config, transformations, t_params, tb_logger = pretrain_routine(args)\n",
    "    \n",
    "\n",
    "# t_ds, val_ds = dataset.get_()\n",
    "# config[\"dataset\"].keys()\n",
    "\n",
    "ecg_datamodule = ECGDataModule(config, transformations, t_params)\n",
    "\n",
    "train_loader = ecg_datamodule.train_dataloader()\n",
    "\n",
    "print('batches in pre-train training loader', len(train_loader))\n",
    "# for item in train_loader:\n",
    "#     print(len(item))\n",
    "#     print(len(item[0]))\n",
    "#     print(item[0][0].shape)\n",
    "#     print(item[1])\n",
    "#     break\n",
    "    \n",
    "valid_loader_self, train_loader_sup, valid_loader_sup = ecg_datamodule.val_dataloader()\n",
    "\n",
    "\n",
    "print('batches in pre-train  validation loader', len(valid_loader_self))\n",
    "print('batches in supervised training loader', len(train_loader_sup))\n",
    "print('batches in supervised validation loader', len(valid_loader_sup))\n",
    "\n",
    "test_loader_sup = ecg_datamodule.test_dataloader()\n",
    "print('batches in supervised test loader', len(test_loader_sup))\n",
    "# i use 3 annotated datasets? why is is executed 4 times? 1 times in set params\n",
    "\n",
    "\n",
    "    \n",
    "# equal to the old dataloader of ptb except for the label not being one-hot-encoded [1, 0, 0, 0, 0] for each entry\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "2\n",
      "7\n",
      "torch.Size([512, 1, 250])\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "torch.Size([512, 3])\n"
     ]
    }
   ],
   "source": [
    "# checking the 3 validation loaders\n",
    "for i, batch in enumerate(valid_loader_self):\n",
    "    print('batch', i)\n",
    "    print(len(batch)) # batch is a tuple (list of tensors, labels)\n",
    "    print(len(batch[0])) # batch[0] is list of 7 tensors from the transforms\n",
    "    print(batch[0][0].shape)   \n",
    "    print(batch[1]) # the labels, lets one-hot encode them into [[1, 0, 0], [0, 0, 1].... etc.]\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Bd11eFuyw0WD",
    "outputId": "464bef56-8aac-45d6-c467-39527adad6eb"
   },
   "outputs": [],
   "source": [
    "# !taskkill /F /IM tensorboard.exe\n",
    "\n",
    "# !tensorboard --logdir=lightning_logs/ --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
